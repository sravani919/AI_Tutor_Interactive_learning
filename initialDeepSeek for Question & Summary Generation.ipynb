{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c43f22-6a1b-44fb-9ade-da0a06d3a556",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.11/site-packages (4.48.2)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in ./.local/lib/python3.11/site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.11/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.11/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.11/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12429a97-52e7-48b6-914c-b4de441759b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc492fac0faa4dd3874a6a6327828e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Review questions generated and saved to deepseek_review_questions.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ✅ Load DeepSeek Model\n",
    "model_name = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# ✅ Function to Generate Questions with Time Limit & Better Control\n",
    "def generate_questions_deepseek(chapter_title, chapter_content):\n",
    "    \"\"\"Generate review questions using DeepSeek AI model with improved token control.\"\"\"\n",
    "    \n",
    "    # Limit chapter content to prevent slow execution\n",
    "    truncated_content = chapter_content[:700]  # Keeping it smaller for speed\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following textbook chapter, generate 5 review questions.\n",
    "\n",
    "    Chapter Title: {chapter_title}\n",
    "    Chapter Content:\n",
    "    {truncated_content}\n",
    "\n",
    "    Questions:\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Tokenize & Limit Tokens to Avoid Freezing\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(\"cuda\")\n",
    "    \n",
    "    try:\n",
    "        # ✅ Run Generation with Timeout (Prevents Hanging)\n",
    "        start_time = time.time()\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=250,  # Slightly increased to ensure full questions\n",
    "            pad_token_id=tokenizer.eos_token_id,  # Ensures stopping\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        # Stop if it takes more than 30 seconds per call\n",
    "        if time.time() - start_time > 30:\n",
    "            print(f\"⚠️ Timeout: Skipping {chapter_title} due to long execution time.\")\n",
    "            return [\"Timeout: No questions generated.\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error while generating questions for {chapter_title}: {str(e)}\")\n",
    "        return [\"Error occurred during generation.\"]\n",
    "\n",
    "    # ✅ Decode Response\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text.strip().split(\"\\n\")\n",
    "\n",
    "# ✅ Load Structured Textbook Data\n",
    "with open(\"structured_textbook.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    textbook_data = json.load(file)\n",
    "\n",
    "# ✅ Generate Questions for Only a Few Chapters at a Time\n",
    "review_questions = {}\n",
    "chapter_count = 0  # ✅ Add a counter to limit the number of runs per execution\n",
    "\n",
    "for chapter, content in textbook_data.items():\n",
    "    if chapter_count >= 5:  # ✅ Process 5 chapters at a time to prevent overload\n",
    "        break\n",
    "    \n",
    "    questions = generate_questions_deepseek(chapter, \" \".join(content))\n",
    "    review_questions[chapter] = questions\n",
    "    chapter_count += 1  # ✅ Increment counter\n",
    "\n",
    "# ✅ Save Generated Questions as JSON\n",
    "questions_json_path = \"deepseek_review_questions.json\"\n",
    "with open(questions_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(review_questions, json_file, indent=4)\n",
    "\n",
    "print(f\"✅ Review questions generated and saved to {questions_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a6b6d2-101f-4dfa-8d9c-64ecd7615f24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chapter summaries generated and saved to deepseek_chapter_summaries.json\n"
     ]
    }
   ],
   "source": [
    "# ✅ Function to Generate Summaries with Better Speed Control\n",
    "def generate_summary_deepseek(chapter_title, chapter_content):\n",
    "    \"\"\"Generate a summary for a chapter using DeepSeek AI model with improved efficiency.\"\"\"\n",
    "    \n",
    "    # ✅ Reduce text size to avoid infinite generation\n",
    "    truncated_content = chapter_content[:900]  # Reduced for speed\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following textbook chapter in 3-5 sentences:\n",
    "\n",
    "    Chapter Title: {chapter_title}\n",
    "    Chapter Content:\n",
    "    {truncated_content}\n",
    "\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Tokenize & Limit Tokens\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(\"cuda\")\n",
    "    \n",
    "    try:\n",
    "        # ✅ Run Generation with Timeout\n",
    "        start_time = time.time()\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=150,  # Keep short summaries\n",
    "            pad_token_id=tokenizer.eos_token_id, \n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        # Stop if it takes more than 20 seconds\n",
    "        if time.time() - start_time > 20:\n",
    "            print(f\"⚠️ Timeout: Skipping {chapter_title} due to long execution time.\")\n",
    "            return \"Timeout: No summary generated.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error while generating summary for {chapter_title}: {str(e)}\")\n",
    "        return \"Error occurred during summary generation.\"\n",
    "\n",
    "    # ✅ Decode Response\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text.strip()\n",
    "\n",
    "# ✅ Generate Summaries for Only a Few Chapters at a Time\n",
    "chapter_summaries = {}\n",
    "chapter_count = 0  # ✅ Limit processing to 5 chapters per run\n",
    "\n",
    "for chapter, content in textbook_data.items():\n",
    "    if chapter_count >= 5:\n",
    "        break\n",
    "\n",
    "    summary = generate_summary_deepseek(chapter, \" \".join(content))\n",
    "    chapter_summaries[chapter] = summary\n",
    "    chapter_count += 1  # ✅ Increment counter\n",
    "\n",
    "# ✅ Save Generated Summaries as JSON\n",
    "summaries_json_path = \"deepseek_chapter_summaries.json\"\n",
    "with open(summaries_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(chapter_summaries, json_file, indent=4)\n",
    "\n",
    "print(f\"✅ Chapter summaries generated and saved to {summaries_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d17b0702-5b6e-432c-bfa5-2ef7a66b0efa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Chapter  \\\n",
      "0  ©2023 Rice University. Textbook content produc...   \n",
      "1  Attribution 4.0 International License (CC BY 4...   \n",
      "2              1.1 Computing from Inception to Today   \n",
      "3                 1.2 Computer Hardware and Networks   \n",
      "4  1.3 The Internet, Cloud Computing, and the Int...   \n",
      "\n",
      "                                           Questions  \n",
      "0  Based on the following textbook chapter, gener...  \n",
      "1  Based on the following textbook chapter, gener...  \n",
      "2  Based on the following textbook chapter, gener...  \n",
      "3  Based on the following textbook chapter, gener...  \n",
      "4  Based on the following textbook chapter, gener...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>©2023 Rice University. Textbook content produc...</td>\n",
       "      <td>Based on the following textbook chapter, gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attribution 4.0 International License (CC BY 4...</td>\n",
       "      <td>Based on the following textbook chapter, gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1 Computing from Inception to Today</td>\n",
       "      <td>Based on the following textbook chapter, gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2 Computer Hardware and Networks</td>\n",
       "      <td>Based on the following textbook chapter, gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3 The Internet, Cloud Computing, and the Int...</td>\n",
       "      <td>Based on the following textbook chapter, gener...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Chapter  \\\n",
       "0  ©2023 Rice University. Textbook content produc...   \n",
       "1  Attribution 4.0 International License (CC BY 4...   \n",
       "2              1.1 Computing from Inception to Today   \n",
       "3                 1.2 Computer Hardware and Networks   \n",
       "4  1.3 The Internet, Cloud Computing, and the Int...   \n",
       "\n",
       "                                           Questions  \n",
       "0  Based on the following textbook chapter, gener...  \n",
       "1  Based on the following textbook chapter, gener...  \n",
       "2  Based on the following textbook chapter, gener...  \n",
       "3  Based on the following textbook chapter, gener...  \n",
       "4  Based on the following textbook chapter, gener...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ Load Generated Questions JSON\n",
    "with open(\"deepseek_review_questions.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    review_questions = json.load(file)\n",
    "\n",
    "# ✅ Convert to DataFrame for Better Visualization\n",
    "df = pd.DataFrame([\n",
    "    {\"Chapter\": chapter, \"Questions\": \"\\n\".join(questions)}\n",
    "    for chapter, questions in review_questions.items()\n",
    "])\n",
    "\n",
    "# ✅ Display the first few rows of the DataFrame\n",
    "print(df.head())  # Shows first 5 rows\n",
    "\n",
    "# ✅ If using Jupyter Notebook, use this for better visualization\n",
    "from IPython.display import display\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "177f0efb-52d6-47cf-82bd-d36ac05e9ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chatbot dataset created and saved as chatbot_training_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load generated questions and summaries\n",
    "questions_file = \"deepseek_review_questions.json\"\n",
    "summaries_file = \"deepseek_chapter_summaries.json\"\n",
    "output_file = \"chatbot_training_data.jsonl\"\n",
    "\n",
    "try:\n",
    "    with open(questions_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        review_questions = json.load(file)\n",
    "\n",
    "    with open(summaries_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        chapter_summaries = json.load(file)\n",
    "\n",
    "    chatbot_dataset = []\n",
    "\n",
    "    # Merge questions, answers, and summaries\n",
    "    for chapter, questions in review_questions.items():\n",
    "        summary = chapter_summaries.get(chapter, \"No summary available.\")\n",
    "        \n",
    "        for i in range(len(questions) // 2):  # Ensuring questions & answers align\n",
    "            question = questions[i]\n",
    "            answer = questions[i + len(questions) // 2] if i + len(questions) // 2 < len(questions) else \"No answer available.\"\n",
    "\n",
    "            chatbot_dataset.append({\n",
    "                \"chapter\": chapter,\n",
    "                \"summary\": summary,\n",
    "                \"question\": question.strip(),\n",
    "                \"answer\": answer.strip()\n",
    "            })\n",
    "\n",
    "    # ✅ Save as JSONL for better fine-tuning\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as jsonl_file:\n",
    "        for entry in chatbot_dataset:\n",
    "            jsonl_file.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ Chatbot dataset created and saved as {output_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ File not found: {e}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"❌ Error decoding JSON.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Unexpected error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f1a9c14-3f8a-47eb-b38f-8d337d37e401",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Line 1: {\n",
      "🔹 Line 2: \"\\u00a92023 Rice University. Textbook content produced by OpenStax is licensed under a Creative Commons\": [\n",
      "🔹 Line 3: \"Based on the following textbook chapter, generate 5 review questions.\",\n",
      "🔹 Line 4: \"\",\n",
      "🔹 Line 5: \"    Chapter Title: \\u00a92023 Rice University. Textbook content produced by OpenStax is licensed under a Creative Commons\",\n",
      "🔹 Line 6: \"    Chapter Content:\",\n",
      "🔹 Line 7: \"    \",\n",
      "🔹 Line 8: \"\",\n",
      "🔹 Line 9: \"    Questions:\",\n",
      "🔹 Line 10: \"    1. What is the purpose of the chapter?\",\n",
      "🔹 Line 11: \"    2. What is the main idea of the chapter?\",\n",
      "🔹 Line 12: \"    3. What are the key concepts that the chapter discusses?\",\n",
      "🔹 Line 13: \"    4. What are the key takeaways from the chapter?\",\n",
      "🔹 Line 14: \"    5. What are the applications of the concepts discussed in the chapter?\",\n",
      "🔹 Line 15: \"\",\n",
      "🔹 Line 16: \"    Answers:\",\n",
      "🔹 Line 17: \"    1. The purpose of the chapter is to provide a comprehensive overview of the topic.\",\n",
      "🔹 Line 18: \"    2. The main idea of the chapter is to understand the concept of copyright and its implications on digital content.\",\n",
      "🔹 Line 19: \"    3. The key concepts that the chapter discusses include copyright, digital content, and the legal implications of copyright.\",\n",
      "🔹 Line 20: \"    4. The key takeaways from the chapter include understanding the importance of copyright and the legal implications of digital content.\",\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"deepseek_review_questions.json\"\n",
    "\n",
    "# Read and display the first few lines\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= 20:  # Limit to 20 lines for preview\n",
    "            break\n",
    "        print(f\"🔹 Line {i+1}: {line.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42031831-3c56-4c92-87a0-b7abd176f41d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully saved cleaned data to cleaned_review_questions.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# File paths\n",
    "input_file = \"deepseek_review_questions.json\"\n",
    "output_file = \"cleaned_review_questions.csv\"\n",
    "\n",
    "# Load JSON file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)  # Load entire JSON object\n",
    "\n",
    "# Prepare list for cleaned data\n",
    "cleaned_data = []\n",
    "\n",
    "# Process each chapter's questions and answers\n",
    "for chapter, content in data.items():\n",
    "    if isinstance(content, list):  # Ensure content is a list\n",
    "        questions = []\n",
    "        answers = []\n",
    "        current_section = None\n",
    "\n",
    "        # Parse the structured text inside the list\n",
    "        for line in content:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line.startswith(\"Questions:\"):\n",
    "                current_section = \"questions\"\n",
    "            elif line.startswith(\"Answers:\"):\n",
    "                current_section = \"answers\"\n",
    "            elif line and current_section == \"questions\":\n",
    "                questions.append(line)\n",
    "            elif line and current_section == \"answers\":\n",
    "                answers.append(line)\n",
    "\n",
    "        # Ensure questions and answers align\n",
    "        for i in range(min(len(questions), len(answers))):\n",
    "            cleaned_data.append({\n",
    "                \"chapter\": chapter,\n",
    "                \"question\": questions[i],\n",
    "                \"answer\": answers[i]\n",
    "            })\n",
    "\n",
    "# Save cleaned data to CSV\n",
    "if cleaned_data:\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "        fieldnames = [\"chapter\", \"question\", \"answer\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        writer.writerows(cleaned_data)\n",
    "\n",
    "    print(f\"✅ Successfully saved cleaned data to {output_file}\")\n",
    "else:\n",
    "    print(\"⚠️ No valid data found after processing.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46f678a1-8ede-4a17-b482-0157ad521b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>©2023 Rice University. Textbook content produc...</td>\n",
       "      <td>1. What is the purpose of the chapter?</td>\n",
       "      <td>1. The purpose of the chapter is to provide a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>©2023 Rice University. Textbook content produc...</td>\n",
       "      <td>2. What is the main idea of the chapter?</td>\n",
       "      <td>2. The main idea of the chapter is to understa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>©2023 Rice University. Textbook content produc...</td>\n",
       "      <td>3. What are the key concepts that the chapter ...</td>\n",
       "      <td>3. The key concepts that the chapter discusses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>©2023 Rice University. Textbook content produc...</td>\n",
       "      <td>4. What are the key takeaways from the chapter?</td>\n",
       "      <td>4. The key takeaways from the chapter include ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>©2023 Rice University. Textbook content produc...</td>\n",
       "      <td>5. What are the applications of the concepts d...</td>\n",
       "      <td>5. The applications of the concepts discussed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Attribution 4.0 International License (CC BY 4...</td>\n",
       "      <td>1. What is the purpose of the CC BY 4.0 license?</td>\n",
       "      <td>1. The CC BY 4.0 license allows for the free r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Attribution 4.0 International License (CC BY 4...</td>\n",
       "      <td>2. What are the conditions of the CC BY 4.0 li...</td>\n",
       "      <td>2. The conditions of the CC BY 4.0 license tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Attribution 4.0 International License (CC BY 4...</td>\n",
       "      <td>3. What is the purpose of the attribution \"Acc...</td>\n",
       "      <td>3. The purpose of the attribution \"Access for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.1 Computing from Inception to Today</td>\n",
       "      <td>1. What is the first computer that was used pr...</td>\n",
       "      <td>1. IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.1 Computing from Inception to Today</td>\n",
       "      <td>2. Name one key company that was a significant...</td>\n",
       "      <td>2. Hewlett Packard, Xerox, Apple, and Microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.1 Computing from Inception to Today</td>\n",
       "      <td>3. What is the significance of the microproces...</td>\n",
       "      <td>3. It allowed computers to become available to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.1 Computing from Inception to Today</td>\n",
       "      <td>4. What are the main advantages of computing t...</td>\n",
       "      <td>4. It increased efficiencies, decreased errors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.1 Computing from Inception to Today</td>\n",
       "      <td>5. What are the key technologies in computing?</td>\n",
       "      <td>5. Mobile devices, digital imaging, and machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.2 Computer Hardware and Networks</td>\n",
       "      <td>1. What are the hardware components that make ...</td>\n",
       "      <td>1. The hardware components that make up a comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.2 Computer Hardware and Networks</td>\n",
       "      <td>2. What is the information processing cycle?</td>\n",
       "      <td>2. Computers process and store data through th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.2 Computer Hardware and Networks</td>\n",
       "      <td>3. What are networks and why are they important?</td>\n",
       "      <td>3. Networks are connections of two or more com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.2 Computer Hardware and Networks</td>\n",
       "      <td>4. What are the basic components of a network?</td>\n",
       "      <td>4. The basic components of a network include r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.2 Computer Hardware and Networks</td>\n",
       "      <td>5. What is the difference between a LAN and a ...</td>\n",
       "      <td>5.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.3 The Internet, Cloud Computing, and the Int...</td>\n",
       "      <td>1. What is the main difference between the int...</td>\n",
       "      <td>1. The internet of things (IoT) is a network o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.3 The Internet, Cloud Computing, and the Int...</td>\n",
       "      <td>2. What is the role of HTML, URL, and DNS in t...</td>\n",
       "      <td>2. HTML, or HyperText Markup Language, is used...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              chapter  \\\n",
       "0   ©2023 Rice University. Textbook content produc...   \n",
       "1   ©2023 Rice University. Textbook content produc...   \n",
       "2   ©2023 Rice University. Textbook content produc...   \n",
       "3   ©2023 Rice University. Textbook content produc...   \n",
       "4   ©2023 Rice University. Textbook content produc...   \n",
       "5   Attribution 4.0 International License (CC BY 4...   \n",
       "6   Attribution 4.0 International License (CC BY 4...   \n",
       "7   Attribution 4.0 International License (CC BY 4...   \n",
       "8               1.1 Computing from Inception to Today   \n",
       "9               1.1 Computing from Inception to Today   \n",
       "10              1.1 Computing from Inception to Today   \n",
       "11              1.1 Computing from Inception to Today   \n",
       "12              1.1 Computing from Inception to Today   \n",
       "13                 1.2 Computer Hardware and Networks   \n",
       "14                 1.2 Computer Hardware and Networks   \n",
       "15                 1.2 Computer Hardware and Networks   \n",
       "16                 1.2 Computer Hardware and Networks   \n",
       "17                 1.2 Computer Hardware and Networks   \n",
       "18  1.3 The Internet, Cloud Computing, and the Int...   \n",
       "19  1.3 The Internet, Cloud Computing, and the Int...   \n",
       "\n",
       "                                             question  \\\n",
       "0              1. What is the purpose of the chapter?   \n",
       "1            2. What is the main idea of the chapter?   \n",
       "2   3. What are the key concepts that the chapter ...   \n",
       "3     4. What are the key takeaways from the chapter?   \n",
       "4   5. What are the applications of the concepts d...   \n",
       "5    1. What is the purpose of the CC BY 4.0 license?   \n",
       "6   2. What are the conditions of the CC BY 4.0 li...   \n",
       "7   3. What is the purpose of the attribution \"Acc...   \n",
       "8   1. What is the first computer that was used pr...   \n",
       "9   2. Name one key company that was a significant...   \n",
       "10  3. What is the significance of the microproces...   \n",
       "11  4. What are the main advantages of computing t...   \n",
       "12     5. What are the key technologies in computing?   \n",
       "13  1. What are the hardware components that make ...   \n",
       "14       2. What is the information processing cycle?   \n",
       "15   3. What are networks and why are they important?   \n",
       "16     4. What are the basic components of a network?   \n",
       "17  5. What is the difference between a LAN and a ...   \n",
       "18  1. What is the main difference between the int...   \n",
       "19  2. What is the role of HTML, URL, and DNS in t...   \n",
       "\n",
       "                                               answer  \n",
       "0   1. The purpose of the chapter is to provide a ...  \n",
       "1   2. The main idea of the chapter is to understa...  \n",
       "2   3. The key concepts that the chapter discusses...  \n",
       "3   4. The key takeaways from the chapter include ...  \n",
       "4   5. The applications of the concepts discussed ...  \n",
       "5   1. The CC BY 4.0 license allows for the free r...  \n",
       "6   2. The conditions of the CC BY 4.0 license tha...  \n",
       "7   3. The purpose of the attribution \"Access for ...  \n",
       "8                                              1. IBM  \n",
       "9     2. Hewlett Packard, Xerox, Apple, and Microsoft  \n",
       "10  3. It allowed computers to become available to...  \n",
       "11  4. It increased efficiencies, decreased errors...  \n",
       "12  5. Mobile devices, digital imaging, and machin...  \n",
       "13  1. The hardware components that make up a comp...  \n",
       "14  2. Computers process and store data through th...  \n",
       "15  3. Networks are connections of two or more com...  \n",
       "16  4. The basic components of a network include r...  \n",
       "17                                                 5.  \n",
       "18  1. The internet of things (IoT) is a network o...  \n",
       "19  2. HTML, or HyperText Markup Language, is used...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"cleaned_review_questions.csv\")\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "138eb978-26ea-44e8-b15a-58d3ddaedb15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Incomplete Answers Found:\n",
      "Empty DataFrame\n",
      "Columns: [chapter, question, answer]\n",
      "Index: []\n",
      "✅ Flagged rows saved to flagged_review_questions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned CSV file\n",
    "csv_path = \"cleaned_review_questions.csv\"  # Update this path if needed\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Check for incomplete or empty answers\n",
    "incomplete_answers_df = df[df['answer'].isna() | (df['answer'].str.strip() == '')]\n",
    "\n",
    "# Save flagged rows to a separate CSV file\n",
    "flagged_csv_path = \"flagged_review_questions.csv\"\n",
    "incomplete_answers_df.to_csv(flagged_csv_path, index=False)\n",
    "\n",
    "# Display flagged rows\n",
    "print(\"⚠️ Incomplete Answers Found:\")\n",
    "print(incomplete_answers_df)\n",
    "\n",
    "print(f\"✅ Flagged rows saved to {flagged_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
